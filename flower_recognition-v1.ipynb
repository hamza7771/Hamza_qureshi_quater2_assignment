{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M5vi7vccR3Y",
        "outputId": "d78ec997-9c9a-4330-f09c-e5cdbaee70f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GTY3RGMctSj",
        "outputId": "c22606d9-8882-4b85-846b-7e59c8493c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI Learning Hard MODE/FlowerRecognition/flowers\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/AI Learning Hard MODE/FlowerRecognition/flowers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWTa089cckGD",
        "outputId": "8fd4a771-ab98-4453-f093-15ab036cb8bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sunflower', 'rose', 'tulip', 'daisy', 'dandelion', 'rose.jpg', 'dandelion.jpg', 'A2.jpg']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir('../flowers'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyJ9ds7fc9Vv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBPyLlYzX3XI",
        "outputId": "fada72b0-88ab-4754-d99e-b76e29e740fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 300 images belonging to 5 classes.\n",
            "Found 200 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.4\n",
        "        )\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '../flowers',\n",
        "        target_size=(320, 240),\n",
        "        batch_size=32,\n",
        "        subset='training',\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "        )\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '../flowers',\n",
        "        target_size=(320, 240),\n",
        "        batch_size=32,\n",
        "        subset='validation',\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "        )\n",
        "\n",
        "#model.fit(train_generator,steps_per_epoch=2000,epochs=50,validation_data=validation_generator,validation_steps=800)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35mKSC6ndAcs",
        "outputId": "d3d226e3-e99a-464d-88cd-c18d3c663964"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "keras.preprocessing.image.DirectoryIterator"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HyA0iFwz3a3",
        "outputId": "860ab9e8-e28b-47c5-8d9c-128ae3eefeae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 318, 238, 256)     7168      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 159, 119, 256)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 157, 117, 256)     590080    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 78, 58, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 76, 56, 128)       295040    \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 38, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 36, 26, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 18, 13, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 29952)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 29952)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                1916992   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,957,189\n",
            "Trainable params: 2,957,189\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(256,(3,3),activation='relu',input_shape=(320,240,3)))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dense(5,activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILbe6o1ygtAa"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzL_SNoqhV46",
        "outputId": "e7d0bc77-758e-48dc-a294-8543a48f9a38"
      },
      "outputs": [],
      "source": [
        "with tensorflow.device ('/device:GPU:0'):\n",
        "  results=model.fit(train_generator,steps_per_epoch=10,epochs=50,validation_data=validation_generator,validation_steps=10,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YThmE2iEz3b3"
      },
      "outputs": [],
      "source": [
        "model.evaluate(validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PLjCv71ot0A"
      },
      "outputs": [],
      "source": [
        "print(os.listdir('../flowers'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFdp6jHon2qP"
      },
      "outputs": [],
      "source": [
        "#To resize original image to standard format and saving it\n",
        "from PIL import Image\n",
        "img1 = Image.open('dandelion.jpg')\n",
        "imResize = img1.resize((240,320), Image.ANTIALIAS)\n",
        "imResize.save('A2.jpg', 'JPEG', quality=90)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MrxOMqgpFqa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "predictimg=cv2.imread(\"A2.jpg\",1)\n",
        "predictimg=np.array(predictimg)\n",
        "plt.imshow(predictimg)\n",
        "predictimg=predictimg/255.0\n",
        "\n",
        "predictimg = np.expand_dims(predictimg, axis=0)\n",
        "predictimg.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR1DNaFYpXTZ"
      },
      "outputs": [],
      "source": [
        "predition=model.predict(predictimg)\n",
        "species=['tulip','sunflower', 'rose', 'dandelion', 'daisy']\n",
        "predition=np.squeeze(predition)\n",
        "print(predition)\n",
        "predIndex=np.argmax(predition)\n",
        "print(\"The Species of given image is\",species[predIndex])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3TMJAROujlO"
      },
      "outputs": [],
      "source": [
        "plt.plot(results.history['accuracy'])\n",
        "plt.plot(results.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqYChTbneA3C"
      },
      "outputs": [],
      "source": [
        "# def read_images(directory):\n",
        "#   for img in glob.glob(directory+\"/*.jpg*\"):\n",
        "#     image=cv2.imread(img)\n",
        "#     resized_img=cv2.resize(image/255,(240,320))\n",
        "#     yield resized_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA7iodfF2Fdj"
      },
      "outputs": [],
      "source": [
        "# resized_img1=np.array(list(read_images(IMG_DIR1)))\n",
        "# resized_img2=np.array(list(read_images(IMG_DIR2)))\n",
        "# resized_img3=np.array(list(read_images(IMG_DIR3)))\n",
        "# resized_img4=np.array(list(read_images(IMG_DIR4)))\n",
        "# resized_img5=np.array(list(read_images(IMG_DIR5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdAIzGTl0MG-"
      },
      "outputs": [],
      "source": [
        "\n",
        "#resized_img5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57K6ST9egE52"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA9V10d8mWiJ"
      },
      "outputs": [],
      "source": [
        "# label1=np.ones((resized_img1.shape[0],1))\n",
        "# label2=np.ones((resized_img2.shape[0],1))*2\n",
        "# label3=np.ones((resized_img3.shape[0],1))*3\n",
        "# label4=np.ones((resized_img4.shape[0],1))*4\n",
        "# label5=np.ones((resized_img5.shape[0],1))*5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGUyah0RgFWh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtP2-EsLfL3M"
      },
      "outputs": [],
      "source": [
        "# data=np.concatenate((resized_img1,resized_img2,resized_img3,resized_img4,resized_img5))\n",
        "# label=np.concatenate((label1,label2,label3,label4,label5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELHZu21531pE"
      },
      "outputs": [],
      "source": [
        "# np.random.seed(101)\n",
        "# mask=np.random.rand(len(data)) < 0.7\n",
        "# train_data= data[mask]\n",
        "# test_data=data[~mask]\n",
        "# train_label= label[mask]\n",
        "# test_label=label[~mask]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDdqZVQQJZ4R"
      },
      "outputs": [],
      "source": [
        "#print(test_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cNDATZoLe95"
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras.utils import to_categorical\n",
        "#train_label1=to_categorical(train_label)\n",
        "#test_label1=to_categorical(test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-1SmpZFLf6P"
      },
      "outputs": [],
      "source": [
        "#train_label1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jddKyWMLgBi"
      },
      "outputs": [],
      "source": [
        "# from keras import models\n",
        "# from keras import layers\n",
        "# model=models.Sequential()\n",
        "# model.add(layers.Dense(64,activation='relu',input_shape=(320*20*3),))\n",
        "# model.add(layers.Dense(64,activation='relu'))\n",
        "# model.add(layers.Dense(64,activation='softmax'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "flowerSelfWritten Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
